{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import string\n",
    "import datetime\n",
    "import re\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#modeling imports\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "#tf imports\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_recall_fscore_support, classification_report, accuracy_score\n",
    "\n",
    "\n",
    "#multinomial nb\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from scipy.sparse.linalg import svds\n",
    "from preprocc import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data()\n",
    "X_train, X_test = preprocess(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221131 first!!!\n"
     ]
    }
   ],
   "source": [
    "from preprocc import *\n",
    "train_data, test_data = tokenize(X_train, X_test)\n",
    "model = eight_way(train_data, test_data, y_train, y_test, batch_size=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-bff0b629b079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#score on the test set!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#score on the test set! \n",
    "score = model.evaluate(test_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic label acc: 91.06%\n"
     ]
    }
   ],
   "source": [
    "print(\"toxic label %s: %.2f%%\" % (model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train models for all the other labels \n",
    "y_train\n",
    "labels = y_train.columns\n",
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================\n",
      "====================================\n",
      "starting fit on toxic\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "starting fit on severe_toxic\n",
      "====================================\n",
      "====================================\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/3\n",
      "111699/111699 [==============================] - 1719s 15ms/step - loss: 0.0356 - acc: 0.9901 - val_loss: 0.0246 - val_acc: 0.9904\n",
      "Epoch 2/3\n",
      "111699/111699 [==============================] - 1850s 17ms/step - loss: 0.0205 - acc: 0.9915 - val_loss: 0.0255 - val_acc: 0.9908\n",
      "Epoch 3/3\n",
      "111699/111699 [==============================] - 2209s 20ms/step - loss: 0.0147 - acc: 0.9936 - val_loss: 0.0293 - val_acc: 0.9900\n",
      "Saved severe_toxic to disk\n",
      "63978/63978 [==============================] - 81s 1ms/step\n",
      "severe_toxic acc: 98.44%\n",
      "====================================\n",
      "====================================\n",
      "done with severe_toxic starting next fit\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "starting fit on obscene\n",
      "====================================\n",
      "====================================\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/3\n",
      "111699/111699 [==============================] - 2180s 20ms/step - loss: 0.0821 - acc: 0.9750 - val_loss: 0.0540 - val_acc: 0.9806\n",
      "Epoch 2/3\n",
      "111699/111699 [==============================] - 1891s 17ms/step - loss: 0.0431 - acc: 0.9841 - val_loss: 0.0536 - val_acc: 0.9810\n",
      "Epoch 3/3\n",
      "111699/111699 [==============================] - 1759s 16ms/step - loss: 0.0299 - acc: 0.9887 - val_loss: 0.0591 - val_acc: 0.9797\n",
      "Saved obscene to disk\n",
      "63978/63978 [==============================] - 86s 1ms/step\n",
      "obscene acc: 94.77%\n",
      "====================================\n",
      "====================================\n",
      "done with obscene starting next fit\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "starting fit on threat\n",
      "====================================\n",
      "====================================\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/3\n",
      "111699/111699 [==============================] - 1750s 16ms/step - loss: 0.0201 - acc: 0.9967 - val_loss: 0.0120 - val_acc: 0.9973\n",
      "Epoch 2/3\n",
      "111699/111699 [==============================] - 1751s 16ms/step - loss: 0.0094 - acc: 0.9974 - val_loss: 0.0098 - val_acc: 0.9972\n",
      "Epoch 3/3\n",
      "111699/111699 [==============================] - 1830s 16ms/step - loss: 0.0053 - acc: 0.9982 - val_loss: 0.0109 - val_acc: 0.9970\n",
      "Saved threat to disk\n",
      "63978/63978 [==============================] - 95s 1ms/step\n",
      "threat acc: 99.58%\n",
      "====================================\n",
      "====================================\n",
      "done with threat starting next fit\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "starting fit on insult\n",
      "====================================\n",
      "====================================\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/3\n",
      "111699/111699 [==============================] - 1819s 16ms/step - loss: 0.0921 - acc: 0.9693 - val_loss: 0.0713 - val_acc: 0.9719\n",
      "Epoch 2/3\n",
      "111699/111699 [==============================] - 1828s 16ms/step - loss: 0.0556 - acc: 0.9782 - val_loss: 0.0728 - val_acc: 0.9735\n",
      "Epoch 3/3\n",
      "111699/111699 [==============================] - 1850s 17ms/step - loss: 0.0402 - acc: 0.9839 - val_loss: 0.0828 - val_acc: 0.9707\n",
      "Saved insult to disk\n",
      "63978/63978 [==============================] - 91s 1ms/step\n",
      "insult acc: 94.29%\n",
      "====================================\n",
      "====================================\n",
      "done with insult starting next fit\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "====================================\n",
      "starting fit on identity_hate\n",
      "====================================\n",
      "====================================\n",
      "Train on 111699 samples, validate on 47872 samples\n",
      "Epoch 1/3\n",
      "111699/111699 [==============================] - 1735s 16ms/step - loss: 0.0396 - acc: 0.9914 - val_loss: 0.0303 - val_acc: 0.9913\n",
      "Epoch 2/3\n",
      "111699/111699 [==============================] - 1687s 15ms/step - loss: 0.0207 - acc: 0.9932 - val_loss: 0.0285 - val_acc: 0.9916\n",
      "Epoch 3/3\n",
      "111699/111699 [==============================] - 9192s 82ms/step - loss: 0.0119 - acc: 0.9956 - val_loss: 0.0356 - val_acc: 0.9904\n",
      "Saved identity_hate to disk\n",
      "63978/63978 [==============================] - 125s 2ms/step\n",
      "identity_hate acc: 97.70%\n",
      "====================================\n",
      "====================================\n",
      "done with identity_hate starting next fit\n",
      "====================================\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(\"====================================\")\n",
    "    print(\"====================================\")\n",
    "    print(\"starting fit on\", label)\n",
    "    print(\"====================================\")\n",
    "    print(\"====================================\")\n",
    "    if label == 'toxic':\n",
    "        continue #already trained toxic\n",
    "    \n",
    "    #just reset the model, bc idk how to make sure it deletes old fit\n",
    "    model = Sequential()\n",
    "    #first layer is embedding, takes in size of vocab, 100 dim embedding, and 150 which is length of the comment \n",
    "    model.add(Embedding(num_words, 100, input_length=150)) \n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    #fit the data to the next label \n",
    "    model.fit(data, np.array(y_train[label]), validation_split=.3, epochs=3)\n",
    "    model_json = model.to_json()\n",
    "    \n",
    "    name_json = label + '.json'\n",
    "    name_h5 = label + '.h5'\n",
    "    \n",
    "    #save into json file\n",
    "    with open(name_json, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(name_h5)\n",
    "    print(\"Saved\", label,\"to disk\")\n",
    "    \n",
    "    #lastly, evaluate on test \n",
    "    score = model.evaluate(test_data, y_test[label])\n",
    "    print(label,\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n",
    "    print(\"====================================\")\n",
    "    print(\"====================================\")\n",
    "    print(\"done with\", label,\"starting next fit\")\n",
    "    print(\"====================================\")\n",
    "    print(\"====================================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#try # 2 dont use \n",
    "X_train['seq'] = tokenizer.texts_to_sequences(X_train['comment_text'])\n",
    "X_test['seq'] = tokenizer.texts_to_sequences(X_test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length before: 1\n"
     ]
    }
   ],
   "source": [
    "def pad_shorter(arr, max_len):\n",
    "    for n in range(len(arr), max_len):\n",
    "        arr.append(None) \n",
    "    return arr\n",
    "\n",
    "max_len = 100\n",
    "print(\"min length before:\", X_train.seq.map(lambda x: len(x)).min())\n",
    "X_train['seq'] = X_train['seq'].apply(lambda x: pad_shorter(x, max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min length after: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[689, 76, 2, 127, 131, 178, 30, 673, 4512, 120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[96146, 53, 2636, 14, 556, 3810, 74, 4557, 270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[413, 438, 74, 135, 15, 250, 3, 72, 315, 79, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[58, 8, 229, 98, 55, 329, 1437, 16, 2134, 8, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[7, 1678, 20, 30, 3517, 55, 1070, 7, 580, 40, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>[5, 13, 2, 428, 85, 4, 903, 83, 21, 314, 563, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>[7, 57, 17, 4653, 4, 207, 10, 9, 6, 3328, 232,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>[34279, 7331, 5209, 47, 738, 24, 13, 8168, 351...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>[5, 12, 575, 50, 12, 25, 211, 7, 63, 202, 16, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>[5, 8, 135, 60, 68, 7, 253, 8, 588, 64, 5, 30,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...   \n",
       "1       D'aww! He matches this background colour I'm s...   \n",
       "2       Hey man, I'm really not trying to edit war. It...   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4       You, sir, are my hero. Any chance you remember...   \n",
       "...                                                   ...   \n",
       "159566  \":::::And for the second time of asking, when ...   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
       "159569  And it looks like it was actually you who put ...   \n",
       "159570  \"\\nAnd ... I really don't think you understand...   \n",
       "\n",
       "                                                      seq  \n",
       "0       [689, 76, 2, 127, 131, 178, 30, 673, 4512, 120...  \n",
       "1       [96146, 53, 2636, 14, 556, 3810, 74, 4557, 270...  \n",
       "2       [413, 438, 74, 135, 15, 250, 3, 72, 315, 79, 5...  \n",
       "3       [58, 8, 229, 98, 55, 329, 1437, 16, 2134, 8, 6...  \n",
       "4       [7, 1678, 20, 30, 3517, 55, 1070, 7, 580, 40, ...  \n",
       "...                                                   ...  \n",
       "159566  [5, 13, 2, 428, 85, 4, 903, 83, 21, 314, 563, ...  \n",
       "159567  [7, 57, 17, 4653, 4, 207, 10, 9, 6, 3328, 232,...  \n",
       "159568  [34279, 7331, 5209, 47, 738, 24, 13, 8168, 351...  \n",
       "159569  [5, 12, 575, 50, 12, 25, 211, 7, 63, 202, 16, ...  \n",
       "159570  [5, 8, 135, 60, 68, 7, 253, 8, 588, 64, 5, 30,...  \n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"min length after:\", X_train.seq.map(lambda x: len(x)).min())\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length before: 1403\n",
      "max length after: 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>[689, 76, 2, 127, 131, 178, 30, 673, 4512, 120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>[96146, 53, 2636, 14, 556, 3810, 74, 4557, 270...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>[413, 438, 74, 135, 15, 250, 3, 72, 315, 79, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>[58, 8, 229, 98, 55, 329, 1437, 16, 2134, 8, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>[7, 1678, 20, 30, 3517, 55, 1070, 7, 580, 40, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...   \n",
       "1  D'aww! He matches this background colour I'm s...   \n",
       "2  Hey man, I'm really not trying to edit war. It...   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
       "4  You, sir, are my hero. Any chance you remember...   \n",
       "\n",
       "                                                 seq  \n",
       "0  [689, 76, 2, 127, 131, 178, 30, 673, 4512, 120...  \n",
       "1  [96146, 53, 2636, 14, 556, 3810, 74, 4557, 270...  \n",
       "2  [413, 438, 74, 135, 15, 250, 3, 72, 315, 79, 5...  \n",
       "3  [58, 8, 229, 98, 55, 329, 1437, 16, 2134, 8, 6...  \n",
       "4  [7, 1678, 20, 30, 3517, 55, 1070, 7, 580, 40, ...  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trunc_longer(arr, max_len):\n",
    "    if len(arr) > max_len:\n",
    "        arr = arr[:max_len]\n",
    "    return arr\n",
    "\n",
    "max_len = 100\n",
    "print(\"max length before:\", X_train.seq.map(lambda x: len(x)).max())\n",
    "X_train['seq'] = X_train['seq'].apply(lambda x: trunc_longer(x, max_len))\n",
    "print(\"max length after:\", X_train.seq.map(lambda x: len(x)).max())\n",
    "X_train.head()\n",
    "\n",
    "#here all the comments should be the same size. go back and check what the mean/median \n",
    "#length of comment (by word) is, 100 might be a hyperparameter we should tune. \n",
    "#could also be checkign what the lengths are of toxic comments vs. normal comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now, start the RNN model somehow \n",
    "sequences = tokenizer.texts_to_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-659ad5532fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the pandas datasets into a tensor\n",
    "# train = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "# test = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "general notes:\n",
    "\n",
    "i feel like we should train the length of comment as a hyperparameter. need to figure out how long most comments are and set to that, not arbitrarily 150. find most common length, medial length, etc. worried that the current model is cutting off any hashtags at the end, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
