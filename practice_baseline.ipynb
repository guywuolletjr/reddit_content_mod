{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocc import *\n",
    "\n",
    "def baseline_lstm(train_data, test_data, y_train, y_test, batch_size):\n",
    "    global NUM_WORDS\n",
    "    print(NUM_WORDS)\n",
    "    model = Sequential()\n",
    "\n",
    "    #first layer is embedding, takes in size of vocab, 100 dim embedding, and 150 which is length of the comment\n",
    "    model.add(Embedding(NUM_WORDS, 100, input_length=150))\n",
    "    model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(6, activation='sigmoid'))#change to 6\n",
    "    model.summary() #Print model Summary\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    #first run through didn't specify a batch size, probably do that\n",
    "    #on the next try.\n",
    "    model.fit(train_data, np.array(y_train), validation_split=.2, epochs=3, batch_size=batch_size)\n",
    "    \n",
    "    #save json model\n",
    "    baseline_model = model.to_json()\n",
    "    with open(\"models/baseline_lstm.json\", \"w\") as json_file:\n",
    "        json_file.write(baseline_model)\n",
    "\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"models/baseline_lstm.h5\")\n",
    "    print(\"Saved baseline_lstm to disk\")\n",
    "\n",
    "    score = model.evaluate(test_data, y_test, verbose=1)\n",
    "    for i in range(len(model.metrics_names)):\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[i], score[i]*100))\n",
    "\n",
    "    return model, score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text\n",
       "0       Explanation\\nWhy the edits made under my usern...\n",
       "1       D'aww! He matches this background colour I'm s...\n",
       "2       Hey man, I'm really not trying to edit war. It...\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4       You, sir, are my hero. Any chance you remember...\n",
       "...                                                   ...\n",
       "159566  \":::::And for the second time of asking, when ...\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...\n",
       "159569  And it looks like it was actually you who put ...\n",
       "159570  \"\\nAnd ... I really don't think you understand...\n",
       "\n",
       "[159571 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenization...\n",
      "210339 first!!!\n"
     ]
    }
   ],
   "source": [
    "print(\"tokenization...\")\n",
    "train_data, test_data = tokenize_baseline(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ...,   361,   176,   138],\n",
       "       [    0,     0,     0, ...,   294,     9,  3328],\n",
       "       [    0,     0,     0, ...,    11,     2,  1203],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,    15,    37, 10689],\n",
       "       [    0,     0,     0, ...,   409,     6,   552],\n",
       "       [    0,     0,     0, ...,     3,  1363,    12]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model!!!\n",
      "210339\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 100)          21033900  \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 606       \n",
      "=================================================================\n",
      "Total params: 21,114,906\n",
      "Trainable params: 21,114,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/3\n",
      "  5620/127656 [>.............................] - ETA: 48:20 - loss: 0.1674 - acc: 0.9610"
     ]
    }
   ],
   "source": [
    "print(\"model!!!\")\n",
    "model, score = baseline_lstm(train_data, test_data, y_train, y_test, batch_size=20)\n",
    "print(score)\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
