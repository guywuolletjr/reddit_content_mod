{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Isabella_GC/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "preprocessing...\n",
      "lowercase\n",
      "contractions\n",
      "numbers\n",
      "newlines\n",
      "stopwords\n",
      "lemmas\n",
      "tokenization...\n",
      "221131 first!!!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.models import model_from_json\n",
    "from preprocc import *\n",
    "import numpy \n",
    "import os \n",
    "\n",
    "print(\"loading data...\")\n",
    "X_train, y_train, X_test, y_test = load_data()\n",
    "print(\"preprocessing...\")\n",
    "X_train, X_test = preprocess(X_train, X_test)\n",
    "print(\"tokenization...\")\n",
    "train_data, test_data = tokenize(X_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Isabella_GC/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Loaded lstm model from disk\n",
      "Loaded double model from disk\n",
      "Loaded triple model from disk\n",
      "Loaded bi lstm model from disk\n",
      "Loaded gru model from disk\n",
      "Loaded tfidf nn model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open('/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/eight_way.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "eight_way = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "eight_way.load_weights(\"/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/eight_way.h5\")\n",
    "print(\"Loaded lstm model from disk\")\n",
    " \n",
    "\n",
    "#doublelstm \n",
    "json_file = open('/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/double_lstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "double_lstm = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "double_lstm.load_weights(\"/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/double_lstm.h5\")\n",
    "print(\"Loaded double model from disk\")\n",
    "\n",
    "#triplelstm \n",
    "json_file = open('/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/triple_lstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "triple_lstm = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "triple_lstm.load_weights(\"/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/triple_lstm.h5\")\n",
    "print(\"Loaded triple model from disk\")\n",
    " \n",
    "\n",
    "#bilstm\n",
    "json_file = open('/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/bi_lstm.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "bi_lstm = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "bi_lstm.load_weights(\"/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/bi_lstm.h5\")\n",
    "print(\"Loaded bi lstm model from disk\")\n",
    "\n",
    "#gru\n",
    "json_file = open('/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/gru.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "gru = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "gru.load_weights(\"/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/gru.h5\")\n",
    "print(\"Loaded gru model from disk\")\n",
    "\n",
    "#tfidf\n",
    "json_file = open('/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/tfidf_nn_architecture.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "tfidf_nn = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "tfidf_nn.load_weights(\"/Users/Isabella_GC/documents/senioryear/cs230/reddit_content_mod/models/tfidf_nn_weights.h5\")\n",
    "print(\"Loaded tfidf nn model from disk\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating LSTM\n",
      "63978/63978 [==============================] - 78s 1ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b756b840f187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0meight_way_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meight_way\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meight_way\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meight_way\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluating double LSTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'score' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "print(\"Evaluating LSTM\")\n",
    "eight_way.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "eight_way_score = eight_way.evaluate(test_data, y_test, verbose=1)\n",
    "for i in range(len(eight_way.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (eight_way.metrics_names[i], score[i]*100))\n",
    "\n",
    "print(\"Evaluating double LSTM\")\n",
    "double_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "double_lstm_score = double_lstm.evaluate(test_data, y_test, verbose=1)\n",
    "for i in range(len(double_lstm.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (double_lstm.metrics_names[i], score[i]*100))\n",
    "\n",
    "    \n",
    "print(\"Evaluating triple LSTM\")\n",
    "triple_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "triple_lstm_score = triple_lstm.evaluate(test_data, y_test, verbose=1)\n",
    "for i in range(len(triple_lstm.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (triple_lstm.metrics_names[i], score[i]*100))\n",
    "    \n",
    "\n",
    "print(\"Evaluating bidirectional LSTM\")\n",
    "bi_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "bi_lstm_score = bi_lstm.evaluate(test_data, y_test, verbose=1)\n",
    "for i in range(len(bi_lstm.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (bi_lstm.metrics_names[i], score[i]*100))\n",
    "\n",
    "    \n",
    "print(\"Evaluating GRU\")\n",
    "gru.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "gru_score = gru.evaluate(test_data, y_test, verbose=1)\n",
    "for i in range(len(gru.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (gru.metrics_names[i], score[i]*100))\n",
    "\n",
    "\n",
    "print(\"Evaluating TFIDF NN\")\n",
    "tfidf_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "tf_idf_nn_score = tfidf_nn.evaluate(X_test, y_test, verbose=1)\n",
    "for i in range(len(tfidf_nn.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (tfidf_nn.metrics_names[i], score[i]*100))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
